{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Dipj16r6QaE",
        "outputId": "ac936a0d-167d-4ec0-9955-ee52a89261fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-07 22:45:46.490194: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-07 22:45:46.931578: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2023-06-07 22:45:46.931634: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-06-07 22:45:48.387272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-06-07 22:45:48.387487: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-06-07 22:45:48.387512: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.applications.vgg16 import VGG16\n",
        "#from cv2 import imshow\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.optimizers.legacy import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS9p04BCoGwz"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baFTUnJ-K48H"
      },
      "outputs": [],
      "source": [
        "img_height = 256\n",
        "img_width = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHE6Wb0qB5yh"
      },
      "outputs": [],
      "source": [
        "def create_model(input_shape, optimizer='rmsprop', fine_tune=0):\n",
        "  conv_base = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "  if fine_tune > 0:\n",
        "      for layer in conv_base.layers[:-fine_tune]:\n",
        "          layer.trainable = False\n",
        "  else:\n",
        "      for layer in conv_base.layers:\n",
        "          layer.trainable = False\n",
        "\n",
        "  top_model = conv_base.output\n",
        "\n",
        "  top_model = Flatten(name=\"flatten\")(top_model)\n",
        "  top_model = Dense(4096, activation='relu')(top_model)\n",
        "  top_model = Dense(1072, activation='relu')(top_model)\n",
        "  top_model = Dropout(0.2)(top_model)\n",
        "  output_layer = Dense(1, activation='sigmoid')(top_model)\n",
        "  \n",
        "  model = Model(inputs=conv_base.input, outputs=output_layer)\n",
        "\n",
        "  model.compile(optimizer=optimizer, \n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsKodSeGHe1E"
      },
      "outputs": [],
      "source": [
        "#train_ds = train_ds.take(330)\n",
        "#test_ds = test_ds.take(330)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLCXogxljh9g"
      },
      "source": [
        "# Set up N parties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOrRcAgymtTI"
      },
      "outputs": [],
      "source": [
        "# Set number of agents\n",
        "numOfParties = 5\n",
        "\n",
        "# number of dataset examples each agent\n",
        "local_num_examples = [1000, 1000, 1000, 1000, 1000]\n",
        "totNumOfExamples = sum(local_num_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW6XNqCbQgZT"
      },
      "source": [
        "# Model weights aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LPhOmSRDFtU"
      },
      "outputs": [],
      "source": [
        "input_shape = (img_height, img_width, 3)\n",
        "optim_1 = Adam(learning_rate=0.001)\n",
        "n_epochs = 1\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load encrypted model weights"
      ],
      "metadata": {
        "id": "hEcIDA9pN2Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_pickle_files = list(glob.glob('./received_pickles/*'))"
      ],
      "metadata": {
        "id": "WJ4KOHcNQdtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agents_encrypted_weights = []\n",
        "for file_path in list_of_pickle_files:\n",
        "  with open(file_path, 'rb') as file:\n",
        "    loaded_weights = pickle.load(file)\n",
        "    agents_encrypted_weights.append(loaded_weights)"
      ],
      "metadata": {
        "id": "rWrsGbc2Quv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agents_decrypted_weights = []\n",
        "# Decrypt agents weights\n",
        "for agent_encrypted_weights in agents_encrypted_weights:\n",
        "  agents_decrypted_weights.append(HE_decrypt(agent_encrypted_weights))"
      ],
      "metadata": {
        "id": "Wsqe628cRUjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregate model weights"
      ],
      "metadata": {
        "id": "9jZq3SZmN2ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_model = create_model(input_shape, optim_1, fine_tune=0)"
      ],
      "metadata": {
        "id": "y4PEK1xMO9jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGsxPj1cQjNF"
      },
      "outputs": [],
      "source": [
        "# update global model with mean of weights\n",
        "avg_weights = []\n",
        "for j in range(len(agents_decrypted_weights[0])):  # for each layer in the model\n",
        "    layer_weights = [agents_decrypted_weights[i][j] for i in range(len(agents_decrypted_weights))]  # collect this layer's weights from each client\n",
        "    layer_weights_avg = np.average(layer_weights, axis=0, weights=[num / totNumOfExamples for num in local_num_examples])  # compute the weighted average\n",
        "    avg_weights.append(layer_weights_avg)  # append the average weights for this layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_model.set_weights(avg_weights)"
      ],
      "metadata": {
        "id": "sbxH6drKPAiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY5ChQv-He1I"
      },
      "outputs": [],
      "source": [
        "global_model.save(\"model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encrypt model weights and send them to every agents"
      ],
      "metadata": {
        "id": "0o3N-pdYOCBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_weights = global_model.get_weights()\n",
        "encrypted_global_weights = HE_encrypt(global_weights)\n",
        "# Now send the aggregated model weights to every agents"
      ],
      "metadata": {
        "id": "6r_HCbx9YIbu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TS9p04BCoGwz"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}