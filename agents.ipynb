{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Dipj16r6QaE",
        "outputId": "7f5cbc42-1428-47f5-a0b9-de07beaed6ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-07 22:45:46.490194: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-07 22:45:46.931578: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2023-06-07 22:45:46.931634: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-06-07 22:45:48.387272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-06-07 22:45:48.387487: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-06-07 22:45:48.387512: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.applications.vgg16 import VGG16\n",
        "#from cv2 import imshow\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.optimizers.legacy import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmTkAmap4FVd"
      },
      "source": [
        "# Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_HqJhEojcHi",
        "outputId": "e8f5a40e-7786-4435-d4ff-9dfbb736c342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign removed: 0\n",
            "phishing removed: 0\n",
            "trusted_list removed: 0\n",
            "Number of benign images: 3107\n",
            "['/home/haohao/Desktop/Hieu/VisualPhish/benign_test/02673.png', '/home/haohao/Desktop/Hieu/VisualPhish/benign_test/02357.png', '/home/haohao/Desktop/Hieu/VisualPhish/benign_test/00993.PNG', '/home/haohao/Desktop/Hieu/VisualPhish/benign_test/00340.png', '/home/haohao/Desktop/Hieu/VisualPhish/benign_test/01948.png']\n",
            "Number of phishing images: 1195\n",
            "['/home/haohao/Desktop/Hieu/VisualPhish/phishing/docmagic/T52_0.png', '/home/haohao/Desktop/Hieu/VisualPhish/phishing/allegro/T6_8.png', '/home/haohao/Desktop/Hieu/VisualPhish/phishing/allegro/T6_1.png', '/home/haohao/Desktop/Hieu/VisualPhish/phishing/allegro/T6_6.png', '/home/haohao/Desktop/Hieu/VisualPhish/phishing/allegro/T6_3.png']\n",
            "Number of trusted images: 1870\n",
            "['/home/haohao/Desktop/Hieu/VisualPhish/trusted_list/twitter/T136_71.png', '/home/haohao/Desktop/Hieu/VisualPhish/trusted_list/twitter/T136_85.png', '/home/haohao/Desktop/Hieu/VisualPhish/trusted_list/twitter/T136_74.png', '/home/haohao/Desktop/Hieu/VisualPhish/trusted_list/twitter/T136_11.png', '/home/haohao/Desktop/Hieu/VisualPhish/trusted_list/twitter/T136_9.png']\n"
          ]
        }
      ],
      "source": [
        "root_dir = '/home/haohao/Desktop/Hieu/VisualPhish/'\n",
        "dataset_dir_benign = root_dir + 'benign_test'\n",
        "dataset_dir_phishing = root_dir + 'phishing'\n",
        "dataset_dir_trusted = root_dir + 'trusted_list'\n",
        "benign = list(glob.glob(dataset_dir_benign + '/*'))\n",
        "phishing = list(glob.glob(dataset_dir_phishing + '/**/*'))\n",
        "trusted_list = list(glob.glob(dataset_dir_trusted + '/**/*'))\n",
        "\n",
        "cnt = 0\n",
        "for f in benign:\n",
        "  if f.upper().find(\".PNG\") == -1 and f.upper().find(\".JPG\") == -1:\n",
        "    try:\n",
        "      os.remove(f)\n",
        "      cnt += 1\n",
        "    except OSError as e:\n",
        "      print(e)\n",
        "\n",
        "print(\"benign removed: \" + str(cnt))\n",
        "cnt = 0\n",
        "\n",
        "for f in phishing:\n",
        "  if f.upper().find(\".PNG\") == -1 and f.upper().find(\".JPG\") == -1:\n",
        "    try:\n",
        "      os.remove(f)\n",
        "      cnt += 1\n",
        "    except OSError as e:\n",
        "      print(e)\n",
        "\n",
        "print(\"phishing removed: \" + str(cnt))\n",
        "cnt = 0\n",
        "\n",
        "for f in trusted_list:\n",
        "  if f.upper().find(\".PNG\") == -1 and f.upper().find(\".JPG\") == -1:\n",
        "    try:\n",
        "      os.remove(f)\n",
        "      cnt += 1\n",
        "    except OSError as e:\n",
        "      print(e)\n",
        "\n",
        "print(\"trusted_list removed: \" + str(cnt))\n",
        "\n",
        "print('Number of benign images: ' + str(len(benign)))\n",
        "print(benign[:5])\n",
        "print('Number of phishing images: ' + str(len(phishing)))\n",
        "print(phishing[:5])\n",
        "print('Number of trusted images: ' + str(len(trusted_list)))\n",
        "print(trusted_list[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc4nNzj3OmIf"
      },
      "source": [
        "# Load dataset and normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baFTUnJ-K48H"
      },
      "outputs": [],
      "source": [
        "img_height = 256\n",
        "img_width = 256\n",
        "phishing_size = len(phishing)\n",
        "trusted_size = len(trusted_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk_O3heP5Jbz",
        "outputId": "81d67ff0-27f8-490b-bcae-74ef276a0e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1195 files belonging to 155 classes.\n",
            "Using 837 files for training.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-07 22:46:05.188502: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2023-06-07 22:46:05.188551: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2023-06-07 22:46:05.188596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (haohao-virtual-machine): /proc/driver/nvidia/version does not exist\n",
            "2023-06-07 22:46:05.190789: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3107 files belonging to 1 classes.\n",
            "Using 2175 files for training.\n",
            "Found 1870 files belonging to 155 classes.\n",
            "Using 1309 files for training.\n",
            "WARNING:tensorflow:From /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "Found 1195 files belonging to 155 classes.\n",
            "Using 358 files for validation.\n",
            "Found 3107 files belonging to 1 classes.\n",
            "Using 932 files for validation.\n",
            "Found 1870 files belonging to 155 classes.\n",
            "Using 561 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# We can use trusted_list with phishing labels\n",
        "\n",
        "dataseta_train = tf.keras.preprocessing.image_dataset_from_directory(dataset_dir_phishing, validation_split=0.3, subset='training', seed=123, image_size=(img_height, img_width), batch_size=None, labels=[1 for i in range(phishing_size)], label_mode='int')\n",
        "datasetb_train = tf.keras.preprocessing.image_dataset_from_directory(dataset_dir_benign, validation_split=0.3, subset='training', seed=123, image_size=(img_height, img_width), batch_size=None, labels=None)\n",
        "datasetc_train = tf.keras.preprocessing.image_dataset_from_directory(dataset_dir_trusted, validation_split=0.3, subset='training', seed=123, image_size=(img_height, img_width), batch_size=None, labels=[1 for i in range(trusted_size)], label_mode='int')\n",
        "\n",
        "dataseta_train = dataseta_train.map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
        "datasetb_train = datasetb_train.map(lambda x: (x, tf.constant(0.0)))\n",
        "datasetc_train = datasetc_train.map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
        "\n",
        "dataseta_test = tf.keras.preprocessing.image_dataset_from_directory(dataset_dir_phishing, validation_split=0.3, subset='validation', seed=123, image_size=(img_height, img_width), batch_size=None, labels=[1 for i in range(phishing_size)], label_mode='int')\n",
        "datasetb_test = tf.keras.preprocessing.image_dataset_from_directory(dataset_dir_benign, validation_split=0.3, subset='validation', seed=123, image_size=(img_height, img_width), batch_size=None, labels=None)\n",
        "datasetc_test = tf.keras.preprocessing.image_dataset_from_directory(dataset_dir_trusted, validation_split=0.3, subset='validation', seed=123, image_size=(img_height, img_width), batch_size=None, labels=[1 for i in range(trusted_size)], label_mode='int')\n",
        "\n",
        "dataseta_test = dataseta_test.map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
        "datasetb_test = datasetb_test.map(lambda x: (x, tf.constant(0.0)))\n",
        "datasetc_test = datasetc_test.map(lambda x, y: (x, tf.cast(y, tf.float32)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMeNHr1zJIp6"
      },
      "outputs": [],
      "source": [
        "train_ds = dataseta_train.concatenate(datasetb_train).concatenate(datasetc_train)\n",
        "test_ds = dataseta_test.concatenate(datasetb_test).concatenate(datasetc_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMRWLqoRUxcs"
      },
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sOMTht0Vmps"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyLAkU-nwwxb"
      },
      "outputs": [],
      "source": [
        "#train_ds = train_ds.take(330)\n",
        "#test_ds = test_ds.take(330)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "XEhQlvGhxLaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LPhOmSRDFtU"
      },
      "outputs": [],
      "source": [
        "input_shape = (img_height, img_width, 3)\n",
        "optim_1 = Adam(learning_rate=0.001)\n",
        "n_epochs = 1\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_train_ds = train_ds.batch(batch_size)\n",
        "local_test_ds = test_ds.batch(batch_size)"
      ],
      "metadata": {
        "id": "8wx_FIaDDM8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create model"
      ],
      "metadata": {
        "id": "TABPWDv--bWG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHE6Wb0qB5yh"
      },
      "outputs": [],
      "source": [
        "def create_model(input_shape, optimizer='rmsprop', fine_tune=0):\n",
        "  conv_base = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "  if fine_tune > 0:\n",
        "      for layer in conv_base.layers[:-fine_tune]:\n",
        "          layer.trainable = False\n",
        "  else:\n",
        "      for layer in conv_base.layers:\n",
        "          layer.trainable = False\n",
        "\n",
        "  top_model = conv_base.output\n",
        "\n",
        "  top_model = Flatten(name=\"flatten\")(top_model)\n",
        "  top_model = Dense(4096, activation='relu')(top_model)\n",
        "  top_model = Dense(1072, activation='relu')(top_model)\n",
        "  top_model = Dropout(0.2)(top_model)\n",
        "  output_layer = Dense(1, activation='sigmoid')(top_model)\n",
        "  \n",
        "  model = Model(inputs=conv_base.input, outputs=output_layer)\n",
        "\n",
        "  model.compile(optimizer=optimizer, \n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the received model weights and decrypt"
      ],
      "metadata": {
        "id": "0jqikDii-XX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('model_weights_inp.pkl', 'rb') as file:\n",
        "  encrypted_weights = pickle.load(file)\n",
        "\n",
        "# decrypt HE\n",
        "\n",
        "decrypted_weights = HE_decrypt(encrypted_weights)\n"
      ],
      "metadata": {
        "id": "8cV8_wDzCdL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a local model with the decrypted weights received from the aggregation server"
      ],
      "metadata": {
        "id": "W2Mnf3qi-win"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(input_shape, optim_1, fine_tune=0)\n",
        "\n",
        "model.set_weights(decrypted_weights)\n",
        "\n",
        "local_model.fit(local_train_ds, epochs=n_epochs, validation_data=local_test_ds, verbose=1)"
      ],
      "metadata": {
        "id": "o79r-AN7y-2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noeIBVCowwxh"
      },
      "outputs": [],
      "source": [
        "global_model.save(root_dir + \"model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encrypt local model weights and send them to the aggregation server"
      ],
      "metadata": {
        "id": "tt29rDLd_uke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_weights()\n",
        "\n",
        "# encrypt HE\n",
        "\n",
        "encrypted_weights = HE_encrypt(weights)"
      ],
      "metadata": {
        "id": "2n8z6HHbGG3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('model_weights_out.pkl', 'wb') as file:\n",
        "  pickle.dump(encrypted_weights, file)\n",
        "\n",
        "# Now send model_weights_out.pkl to the aggregation server"
      ],
      "metadata": {
        "id": "1PX9dZdZDexd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}